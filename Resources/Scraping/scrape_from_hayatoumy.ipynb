{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53a0766",
   "metadata": {},
   "source": [
    "In this notebook we will be using a script written by GitHub user hayatoumy to scrape perfumes/notes from the website fragrantica.com. Please follow this url to see the original script: https://github.com/hayatoumy/perfume_analysis/blob/master/collecting_data/fragrantica_library.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18eaf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ecccc8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html_content, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Call the function to extract information\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m perfume_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_main_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(perfume_info)\n",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m, in \u001b[0;36mget_main_scope\u001b[1;34m(soup_object)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mReturns perfume name and gender, designer name, family/group of perfume. In that order\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03msoup_object: html content, parsed with BeautifulSoup\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#get perfume name and gender\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# function to get the name of the perfume\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[43msoup_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstyle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclear: left;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# get designer, and perfume family\u001b[39;00m\n\u001b[0;32m     15\u001b[0m main_scope \u001b[38;5;241m=\u001b[39m soup_object\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont-size: 12px;\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# Define the functions to collect specific pieces of the HTML\n",
    "def get_main_scope(soup_object):\n",
    "    \"\"\"\n",
    "    Returns perfume name and gender, designer name, family/group of perfume. In that order\n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    soup_object: html content, parsed with BeautifulSoup\n",
    "    \"\"\"\n",
    "    #get perfume name and gender\n",
    "    # function to get the name of the perfume\n",
    "    name = soup_object.find('h1', {'style' : 'clear: left;'}).text.strip()\n",
    "    \n",
    "    # get designer, and perfume family\n",
    "    main_scope = soup_object.find('p', {'style' : 'font-size: 12px;'})\n",
    "    \n",
    "    designer = main_scope.find('span', {'itemprop' : 'name'}).text.strip()\n",
    "    try: \n",
    "        group = main_scope.find('span' ,{'style' : 'float:right;'}).find('a').text.strip()\n",
    "    except: \n",
    "        group = 'NA'\n",
    "    \n",
    "    return name, designer, group\n",
    "\n",
    "import requests\n",
    "\n",
    "# Assuming 'url' is the URL of the webpage you want to scrape\n",
    "url = 'https://www.fragrantica.com/'\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Call the function to extract information\n",
    "perfume_info = get_main_scope(soup)\n",
    "print(perfume_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a51bda86",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Call the function to extract information\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m accords_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_main_accords\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(accords_info)\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m, in \u001b[0;36mget_main_accords\u001b[1;34m(soup_object)\u001b[0m\n\u001b[0;32m     12\u001b[0m accord_percentage \u001b[38;5;241m=\u001b[39m soup_object\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth: 130px; height: 20px; border: solid 1px #ffffff; border-top: none; position: relative; text-align: center; clear: both; padding: 0;\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# finding position\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[43maccord_percentage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/span\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m s:\n\u001b[0;32m     17\u001b[0m         position \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(accord_percentage[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mindex(s)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Create a function that returns a tuple of note and dominancy\n",
    "def get_main_accords(soup_object):\n",
    "    # grab the main accords piece\n",
    "    accords = soup_object.find_all('div', {'style' : 'width: 130px; height: 20px; border: solid 1px #ffffff; border-top: none; position: relative; text-align: center; clear: both; padding: 0;'})\n",
    "    \n",
    "    notes = []\n",
    "    for i in range(len(accords)):\n",
    "        notes.append(accords[i].find('span', {'style' : 'position: relative; font-weight: bold; z-index: 60;'}).text.strip())\n",
    "\n",
    "        \n",
    "    # grab the dominance scale:\n",
    "    accord_percentage = soup_object.find_all('div', {'style' : 'width: 130px; height: 20px; border: solid 1px #ffffff; border-top: none; position: relative; text-align: center; clear: both; padding: 0;'})\n",
    "    \n",
    "    # finding position\n",
    "    for s in str(accord_percentage[1]).split(';'):\n",
    "        if '/span' in s:\n",
    "            position = str(accord_percentage[1]).split(';').index(s)\n",
    "            \n",
    "    \n",
    "    # find percentages of the accords\n",
    "    percentages = []\n",
    "    for i in range(len(accord_percentage)):\n",
    "        percentages.append( (str(accord_percentage[i]).split(';')[position].split(':')[1][:-2]) ) \n",
    "    \n",
    "    # tuple them together\n",
    "    results = list(zip(notes, percentages))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Call the function to extract information\n",
    "accords_info = get_main_accords(soup)\n",
    "print(accords_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4c27cba",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m num_voters, results, status_full\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Call the function to extract information\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m votes_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_votes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(votes_info)\n",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m, in \u001b[0;36mget_votes\u001b[1;34m(soup_object)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# grab votes piece\u001b[39;00m\n\u001b[0;32m     12\u001b[0m votes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msoup_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiagramresult\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstyle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m i:\n\u001b[0;32m     15\u001b[0m         votes\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;66;03m# [:-2] means take all but the last two characters, coz they are px\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "def get_votes(soup_object):\n",
    "    \"\"\"\n",
    "    Returns three things:\n",
    "    Total number of voters, Opinions, Purchase numbers. In this order\n",
    "    You can index to get only what you want. Example: get_votes(soup)[1] will return Opinions (collective reviews).\n",
    "    \n",
    "    Parameters: \n",
    "    soup_object: BeautifulSoup object, requested and ready.\n",
    "    \"\"\"\n",
    "    \n",
    "    # grab votes piece\n",
    "    votes = []\n",
    "    for i in str(soup_object.find(\"div\", {'id' : 'diagramresult'}))['style'].split(';'):\n",
    "        if 'height' in i:\n",
    "            votes.append(i.split(':')[1][:-2]) # [:-2] means take all but the last two characters, coz they are px\n",
    "            \n",
    "    # grab votes categories piece\n",
    "    vote_categories = soup_object.find_all('div', {'class' : 'votecaption'})\n",
    "    \n",
    "    categories = []\n",
    "    for v in range(len(vote_categories)):\n",
    "        categories.append(vote_categories[v].text)\n",
    "        \n",
    "    \n",
    "    # getting total number of voters\n",
    "    num_voters = soup_object.find('b', {'id' : 'peopleD'}).text\n",
    "    num_voters = int(num_voters)\n",
    "    \n",
    "    \n",
    "    # getting other statistics: \n",
    "    stats = str(soup_object.find('span', {'style' : 'font-size: 10px;'}).text).split('  ')\n",
    "    status = []\n",
    "    status_number = []\n",
    "    for sentence in stats:\n",
    "        status.append(sentence.split(':')[0])\n",
    "        status_number.append(sentence.split(':')[1][1:])\n",
    "     \n",
    "    status_full = list(zip(status, status_number))\n",
    "    \n",
    "    \n",
    "            \n",
    "    # tuple them together\n",
    "    results = list(zip(categories, votes))\n",
    "    \n",
    "#     print(f\"Total Voters: {num_voters}, Purchases: {status_full}\")\n",
    "    return num_voters, results, status_full\n",
    "\n",
    "# Call the function to extract information\n",
    "votes_info = get_votes(soup)\n",
    "print(votes_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854c72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a synopsis and ratings function\n",
    "def get_synopsis(soup_object):\n",
    "    \"\"\"\n",
    "    This function returns the short perfume description, perfume review total out of 5 start, and total number of \n",
    "    voters. In that order. \n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    soup_object: the parsed html content.\n",
    "    \"\"\"\n",
    "    # written short description \n",
    "    synopsis = soup_object.find('div', {'itemprop' : 'description'}).text.strip()\n",
    "    \n",
    "    # rating (out of 5)\n",
    "    rating = soup_object.find('span', {'itemprop' : 'ratingValue'}).text.strip()\n",
    "    \n",
    "    # total number of voters\n",
    "    num_voters = soup_object.find('span', {'itemprop' : 'ratingCount'}).text.strip() # also found from function get_votes(soup_object)[0] it's the first return\n",
    "    \n",
    "    return synopsis, rating, num_voters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eef22932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all of the notes regardless of top, middle, or base\n",
    "#Below is another function get_notes_class() that returns each part: Top, Middle, Base independently\n",
    "def get_all_notes(soup_object):\n",
    "    \"\"\"\n",
    "    Returns a list of all the notes in a perfume; regardless whether it's a Top, Middle or Base note. \n",
    "    Usually, the first four are Top, the second four are Middle, and the all the rest are Base. (Make sure of this!)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    soup_object: parsed html content by BeautifulSoup\n",
    "    \"\"\"\n",
    "    # grabbing the whole rectangle of notes\n",
    "    pyramid = soup_object.find('div', {'style' : 'width: 230px; float: left; text-align: center; clear: left;'})\n",
    "    \n",
    "    # drilling down\n",
    "    all_pyramid = pyramid.find_all('span', {'class' : 'rtgNote'})\n",
    "    \n",
    "    #drilling down to notes names\n",
    "    notes = []\n",
    "    for p in all_pyramid:\n",
    "        notes.append(p.find('img')['bt-xtitle'])\n",
    "        \n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "121a52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes_class(soup_object):\n",
    "    \"\"\"\n",
    "    Returns notes in each class independently. Returns Top, Middle, Base notes. In that order. \n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    soup_object: html content, parsed with BeautifulSoup\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the notes box\n",
    "    notes_box = soup_object.find('div', {'style' : 'width: 230px; float: left; text-align: center; clear: left;'})\\\n",
    "    .find_all('p')  # top notes is [0], middle is [1], and base is [2]\n",
    "    \n",
    "    # get each list section, to drill down on it\n",
    "    top_section = notes_box[0].find_all('span', {'class' : 'rtgNote'})\n",
    "    middle_section = notes_box[1].find_all('span', {'class' : 'rtgNote'})\n",
    "    base_section = notes_box[2].find_all('span', {'class' : 'rtgNote'})\n",
    "        \n",
    "    # drilling down each notes section to get each note name:\n",
    "    top_notes = []\n",
    "    for t in top_section:\n",
    "        top_notes.append(t.find('img')['bt-xtitle'])\n",
    "        \n",
    "    middle_notes = []\n",
    "    for t in middle_section:\n",
    "        middle_notes.append(t.find('img')['bt-xtitle'])\n",
    "        \n",
    "    base_notes = []\n",
    "    for t in base_section:\n",
    "        base_notes.append(t.find('img')['bt-xtitle'])\n",
    "    \n",
    "    return top_notes, middle_notes, base_notes\n",
    "\n",
    "\n",
    "def get_long_sil(soup_object):\n",
    "    \"\"\"\n",
    "    Returns a table of Longevity, and Sillage. In that order. \n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    soup_object: html content, parsed with BeautifulSoup\n",
    "    \"\"\"\n",
    "    \n",
    "    # Longevity table\n",
    "    long_votes_table = soup_object.find('div', {'class' : 'longSilBox effect6'})\\\n",
    "    .find('table', {'class' : 'voteLS long'}).find('tbody').find_all('tr')\n",
    "    \n",
    "    # printing votes, and their count\n",
    "    longevity_votes =[]\n",
    "    for k in long_votes_table:\n",
    "        longevity_votes.append(k.text.split('\\n')[1:3])\n",
    "    \n",
    "    # making the numbers integers\n",
    "    temp_long = [int(i[1]) for i in longevity_votes]\n",
    "    temp_long_votes = [i[0] for i in longevity_votes]\n",
    "    longevity_votes = list(zip(temp_long_votes, temp_long))\n",
    "    \n",
    "    \n",
    "    # Sillage\n",
    "    sil_1 = []\n",
    "    sil_2 = []\n",
    "    for s in soup_object.find('div', {'class' : 'divSil'}).find('table').find_all('tr'):\n",
    "        sil_1.append(s.find('td', {'class' : 'ndSum'}).text.strip())\n",
    "        sil_2.append(s.find('td').text.split('\\n'))\n",
    "\n",
    "    sil_1 = [int(i) for i in sil_1[1:] ]\n",
    "    sil_2 = [i[0] for i in sil_2[1:] ]\n",
    "    \n",
    "    sillage_votes = list(zip(sil_2, sil_1))\n",
    "        \n",
    "    return longevity_votes, sillage_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ddc17cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(soup_object):\n",
    "    \"\"\"\n",
    "    Returns the member id, and reviews text with the user name from each perfume's page. In that order.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    soup_object: html content, parsed by BeautifulSoup\n",
    "    \"\"\"\n",
    "    # get the reviews section\n",
    "    written_reviews_section = soup_object.find('div', {'xmlns' : 'http://www.w3.org/1999/html'})\\\n",
    "    .find_all('div', {'class':'pwq'})\n",
    "    \n",
    "    # get review text\n",
    "    # Note: format is: user\\n\\n\\n\\ntext\n",
    "    reviews = []\n",
    "    for r in written_reviews_section:\n",
    "        reviews.append(r.text.strip())\n",
    "        \n",
    "    member_id = []\n",
    "    for member in written_reviews_section:\n",
    "        member_id.append(member.find('a')['href'].split('/')[2])\n",
    "        \n",
    "    return member_id, reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41cdaa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative functions\n",
    "# alternative to get_notes_class()\n",
    "def get_notes_class_alternative(soup_object):\n",
    "    top_section = soup_object.find('div', \n",
    "                {'style' : 'width: 230px; float: left; text-align: center; clear: left;'})\n",
    "\n",
    "    all_notes_alternative = []\n",
    "    for sp in step_1.find_all('span'):\n",
    "        all_notes_alternative.append(sp.find('img')['bt-xtitle']) # or ['alt'] at the end, both work\n",
    "\n",
    "\n",
    "    return all_notes_alternative\n",
    "                                         \n",
    "                                         \n",
    "\n",
    "#alternative to get_long_sil()\n",
    "def get_main_accords_alternative(soup_object):\n",
    "    \n",
    "    main_accords_public = []\n",
    "    for m in soup_object.find('div', {'id' : 'userMainNotes'}).find_all('img'):\n",
    "        main_accords_public.append(m['alt'])\n",
    "    \n",
    "    return main_accords_public\n",
    "\n",
    "\n",
    "def get_long_sil_alternative(soup_object):\n",
    "    \n",
    "    # for Longevity\n",
    "    long_score_name = []\n",
    "    long_score_value = []\n",
    "    for k in soup_object.find('div', {'class' : 'divLong'}).find('tbody').find_all('tr'):\n",
    "        long_score_name.append(k.find_all('td')[0].text.strip())\n",
    "        long_score_value.append(k.find_all('td')[1].text.strip())\n",
    "\n",
    "    # zip them together to print them\n",
    "    long_scores = list(zip(long_score_name, long_score_value))\n",
    "    \n",
    "    # for Sillage\n",
    "    sil_score_name = ['soft', 'moderate', 'heavy', 'enormous']\n",
    "    sil_score_value = []\n",
    "    for k in soup_object.find('div', {'class' : 'divSil'}).find_all('td', {'class' : 'ndSum'}):\n",
    "        sil_score_value.append(k.text.strip())\n",
    "\n",
    "    sil_scores = list(zip(sil_score_name, sil_score_value))\n",
    "    \n",
    "    return long_scores, sil_scores\n",
    "\n",
    "\n",
    "def get_votes_alternative(soup_object):\n",
    "    \n",
    "    # have it/had it/want it/my signature \n",
    "    # get names, and values of these categories\n",
    "    names = []\n",
    "    values = []\n",
    "    for k in soup_object.find_all('span', {'style' : 'font-size: 10px;'})[0].text.strip().split('  '):\n",
    "        names.append(k.split(':')[0].strip())\n",
    "        values.append(k.split(':')[1].strip())\n",
    "   \n",
    "    buying_votes = list(zip(names, values))\n",
    "    \n",
    "    \n",
    "    # love/like/dislike, winter/spring/summer/fall, day/night\n",
    "    \n",
    "    opinions_percentage = []\n",
    "    for k in BeautifulSoup.prettify((soup_object).find_all('div', {'id' : 'diagramresult'})[0]).split('height:')[2:]:\n",
    "        opinions_percentage.append(k.split(';')[0].strip('px')) # divide this number by 100\n",
    "        \n",
    "    \n",
    "    opinions = list(zip(['Love', 'Like', 'Dislike' 'Winter', 'Spring', 'Summer', 'Fall', 'Day', 'Night'], \n",
    "                       opinions_percentage))\n",
    "    \n",
    "    \n",
    "    return buying_votes, opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63dd0990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting Soup Objects\n",
    "def get_soups(links_list, local_driver):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a list of soup objects for later find and use, handels for error 429 \"Too Many Requests\".\n",
    "    MUST RUN `local_driver = webdriver.Chrome()` BEFORE running this function.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    links_list: a list of links that are healthy and ready to get.\n",
    "    \"\"\"\n",
    "    \n",
    "    from time import sleep\n",
    "    \n",
    "    soup_list = []\n",
    "    for n, link in enumerate(links_list):\n",
    "        local_driver.get(link)\n",
    "        local_soup = BeautifulSoup(local_driver.page_source, 'lxml')\n",
    "        \n",
    "        \n",
    "        if local_soup.find('h1').text == '429 Too Many Requests':\n",
    "            the_429 = True\n",
    "            \n",
    "            while the_429: # means automatically true\n",
    "                sleep(900) # sleep for 15 minutes\n",
    "                local_driver.get(link)\n",
    "                local_soup = BeautifulSoup(local_driver.page_source, 'lxml')\n",
    "                if local_soup.find('h1').text != '429 Too Many Requests':\n",
    "                    soup_list.append(local_soup)\n",
    "                    the_429 = False\n",
    "\n",
    "        \n",
    "        else: \n",
    "            soup_list.append(local_soup)\n",
    "            sleep(7)\n",
    "            # to print which link I'm at, and what is it's index\n",
    "            print(n)\n",
    "            print(link)\n",
    "            print('-----')\n",
    "\n",
    "            \n",
    "            \n",
    "    return soup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbf91c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User hayatoumy did not use or test this function but we will see if its useful for our project:\n",
    "def prettify_save(soup_objects_list, output_file_name):\n",
    "    \"\"\"\n",
    "    Saves the results of get_soup() function to a text file. \n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    soup_object_list: \n",
    "        list of BeautifulSoup objects to be saved to the text file\n",
    "    output_file_name:\n",
    "        entered as string with quotations and with extension .txt , used to name the output text file\n",
    "        \n",
    "    This function can work independent of the rest of the library. \n",
    "        \n",
    "    Note: \n",
    "    Unique to Windows, open() needs argument: encoding = 'utf8' for it to work. \n",
    "    \"\"\"\n",
    "    \n",
    "    prettified_soup = [BeautifulSoup.prettify(k) for k in soup_objects_list]\n",
    "    custom_word_added = [m + 'BREAKHERE' for m in prettified_soup]\n",
    "    one_string = \"\".join(custom_word_added)\n",
    "    \n",
    "    # unique to Windows, open() needs argument: encoding = \"utf8\"\n",
    "    with open(output_file_name, 'w') as file:\n",
    "        file.write(one_string)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb4844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the DataFrames\n",
    "def make_reviews_df(one_prettified_soup):\n",
    "    \"\"\"\n",
    "    Returns one data frame of the customer id, reviews, and few characteristics about the perfume.\n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    one_prettified_soup:\n",
    "        A prettified soup object. Example: the output list of the prettify_save() function above; could be read from a text file.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # preparing the soup_objects\n",
    "    soup_object = BeautifulSoup(one_prettified_soup, 'lxml')\n",
    "    \n",
    "    # gathering the lists\n",
    "    customer_id = get_reviews(soup_object)[0]\n",
    "    review_text = get_reviews(soup_object)[1]\n",
    "\n",
    "    perfume_name = get_main_scope(soup_object)[0]\n",
    "    designer = get_main_scope(soup_object)[1]\n",
    "    group = get_main_scope(soup_object)[2]\n",
    "    \n",
    "    try: \n",
    "        main_accords = get_main_accords(soup_object)\n",
    "    except:\n",
    "        main_accords = 'NA'\n",
    "    \n",
    "    all_notes = get_all_notes(soup_object)\n",
    "\n",
    "    # make the initial df\n",
    "    temp_df = pd.DataFrame({'customer-id' : customer_id, 'review_test' : review_text})\n",
    "    \n",
    "    # add the perfume characteristics to it, to pin down the review\n",
    "    temp_df['perfume_name'] = perfume_name\n",
    "    temp_df['designer'] = designer\n",
    "    temp_df['perfume_group'] = group\n",
    "    temp_df['main_accords'] = [main_accords for i in range(temp_df.shape[0])]\n",
    "    temp_df['all_notes'] = [all_notes for i in range(temp_df.shape[0])] \n",
    "    # making copies of the list, otherwise pandas is trying to put it as a column, and raises lenght conflict\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a375a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fragrantica_library.py file\n",
    "def make_perfume_df(one_prettified_soup):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns one data frame of all the characteristics, and statistics of the perfume.\n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    one_prettified_soup:\n",
    "        A prettified soup object. Example: the output list of the prettify_save() function above; could be read from a text file.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # preparing the soup_objects\n",
    "    soup_object = BeautifulSoup(one_prettified_soup, 'lxml')\n",
    "    \n",
    "    # gathering the lists\n",
    "    perfume_name = get_main_scope(soup_object)[0]\n",
    "    designer = get_main_scope(soup_object)[1]\n",
    "    group = get_main_scope(soup_object)[2]\n",
    "     \n",
    "\n",
    "    try:\n",
    "        main_accords = get_main_accords(soup_object)\n",
    "    except:\n",
    "        try: \n",
    "            main_accords = get_main_accords_alternative(soup_object)\n",
    "        except:\n",
    "            main_accords = 'NA'\n",
    "\n",
    "    try: \n",
    "        top_notes = get_notes_class(soup_object)[0]\n",
    "        middle_notes = get_notes_class(soup_object)[1]\n",
    "        base_notes = get_notes_class(soup_object)[2]\n",
    "    except:\n",
    "        top_notes = 'NA'\n",
    "        middle_notes = 'NA'\n",
    "        base_notes = 'NA'\n",
    "\n",
    "    try:\n",
    "        all_notes = get_all_notes(soup_object)\n",
    "    except: \n",
    "        all_notes = 'NA'\n",
    "\n",
    "    try:     \n",
    "        longevity = get_long_sil_alternative(soup_object)[0]\n",
    "    except:\n",
    "        longevity = 'NA'\n",
    "    \n",
    "    try:\n",
    "        sillage = get_long_sil_alternative(soup_object)[1]\n",
    "    except:\n",
    "        sillage = 'NA'\n",
    "\n",
    "    try: \n",
    "        synopsis = get_synopsis(soup_object)[0]\n",
    "    except:\n",
    "        synopsis = 'NA'\n",
    "    \n",
    "    try:\n",
    "        rating = get_synopsis(soup_object)[1] #overall rating\n",
    "    except:\n",
    "        rating = 'NA'\n",
    "    \n",
    "    try:\n",
    "        num_voters = get_synopsis(soup_object)[2]\n",
    "    except:\n",
    "        num_voters = 'NA'\n",
    "\n",
    "    try: \n",
    "        opinions = get_votes_alternative(soup_object)[1]   \n",
    "    except:\n",
    "        opinions = 'NA'\n",
    "        \n",
    "    try:    \n",
    "        purchases = get_votes_alternative(soup_object)[0]\n",
    "    except:\n",
    "        purchases = 'NA'\n",
    "\n",
    "    \n",
    "    # make the initial df\n",
    "    temp_df_2 = pd.DataFrame({\n",
    "            'perfume_name' : [perfume_name], \n",
    "            'designer' : [designer],\n",
    "            'group' : [group],\n",
    "            'main_accords' : [main_accords],\n",
    "            'all_notes' : [all_notes], \n",
    "            'top_notes' : [top_notes],\n",
    "            'middle_notes' : [middle_notes],\n",
    "            'base_notes' : [base_notes],\n",
    "            'longevity' : [longevity], \n",
    "            'sillage' : [sillage], \n",
    "            'synopsis' : [synopsis],\n",
    "            'overall_rating' : [rating],\n",
    "            'total_num_voters' : [num_voters],\n",
    "            'opinions' : [opinions],\n",
    "            'purchases' : [purchases]\n",
    "        })\n",
    "    # what matters to pandas is each list length. A list of length 1 could be ANY object! could be a dictionary or a \n",
    "    # list of lists or a list of dfs! (well maybe not the latter, don't know)  \n",
    "    return temp_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922b0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
