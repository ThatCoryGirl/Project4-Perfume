{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ade47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a067dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependency for SQLite database\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"../Resources/perfume.db\")\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ae826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all rows from the 'Review_Included' table\n",
    "cur.execute(\"SELECT * FROM Reviews_Included\")\n",
    "\n",
    "# Fetch all rows from the 'Review_Included' table\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fetched data into a pandas DataFrame\n",
    "# Get column names\n",
    "columns = [col[0] for col in cur.description]\n",
    "perfume_df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a6d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns (at this point we have decided to use the main accords in lieu of the top, middle, and base notes for accuracy)\n",
    "columns_to_remove = ['image', 'for_gender', 'description', 'gender_vote', 'price value', 'top notes', 'middle notes', 'base notes']\n",
    "\n",
    "# Remove the specified columns\n",
    "perfume_df = perfume_df.drop(columns=columns_to_remove)\n",
    "\n",
    "# Display the DataFrame after dropping the specified columns\n",
    "perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bbbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threshold for removing rows based on rating\n",
    "rating_threshold = 3.59\n",
    "\n",
    "# Filter the DataFrame to exclude rows with ratings at or below the threshold\n",
    "perfume_df = perfume_df[perfume_df['rating'] > rating_threshold]\n",
    "\n",
    "# Display the DataFrame after removing rows\n",
    "print(perfume_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a663d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threshold for removing rows based on number of votes\n",
    "votes_threshold = 100\n",
    "\n",
    "# Filter the DataFrame to exclude rows with number of votes less than the threshold\n",
    "perfume_df = perfume_df[perfume_df['number_votes'] >= votes_threshold]\n",
    "\n",
    "# Display the DataFrame after removing rows\n",
    "print(perfume_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91228112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the DataFrame to reflect its cleaned state\n",
    "# Make a copy to preserve the original DataFrame\n",
    "cleaned_perfume_df = perfume_df.copy()\n",
    "cleaned_perfume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_perfume_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b938157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working to create a new entry for each scent creating multiple entries for each perfume based on the number of scents in it\n",
    "# Parse the string representations of dictionaries in 'main accords' into separate rows\n",
    "accords_df = cleaned_perfume_df['main accords'].apply(lambda x: pd.Series(eval(x)).items())\n",
    "\n",
    "# Stack the resulting Series to create multiple rows for each perfume\n",
    "accords_df = accords_df.apply(pd.Series).stack().reset_index(level=1, drop=True).reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "accords_df.columns = ['index', 'scent', 'scent_strength']\n",
    "\n",
    "# Merge accords_df with the original DataFrame\n",
    "cleaned_perfume_df = cleaned_perfume_df.merge(accords_df, left_index=True, right_on='index')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "cleaned_perfume_df.drop(['main accords', 'index'], axis=1, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "cleaned_perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef191752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create multiple entries for each perfume based on the number of scents it has from the 'main accords' column\n",
    "perfume_df = cleaned_perfume_df.loc[cleaned_perfume_df.index.repeat(accords_df.shape[1])]\n",
    "perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of perfume_df to ensure uniqueness\n",
    "perfume_df.reset_index(drop=True, inplace=True)\n",
    "perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of accords_df to ensure uniqueness\n",
    "accords_df.reset_index(drop=True, inplace=True)\n",
    "accords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate accords_df with perfume_df\n",
    "cleaned_perfume_df = pd.concat([perfume_df, accords_df], axis=1)\n",
    "cleaned_perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0689bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for scent strength\n",
    "cleaned_perfume_df['scent_strength'] = cleaned_perfume_df['rating'] * cleaned_perfume_df.iloc[:, 7:]\n",
    "cleaned_perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the string representations of dictionaries in 'main accords' into separate columns\n",
    "accords_df = cleaned_perfume_df['main accords'].apply(lambda x: pd.Series(eval(x)))\n",
    "\n",
    "# Create multiple entries for each perfume based on the number of scents it has from the 'main accords' column\n",
    "perfume_df = cleaned_perfume_df.loc[cleaned_perfume_df.index.repeat(accords_df.shape[1])]\n",
    "\n",
    "# Reset index of perfume_df to ensure uniqueness\n",
    "perfume_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reset index of accords_df to ensure uniqueness\n",
    "accords_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate accords_df with perfume_df\n",
    "cleaned_perfume_df = pd.concat([perfume_df, accords_df], axis=1)\n",
    "\n",
    "# Create a new column for scent strength\n",
    "cleaned_perfume_df['scent_strength'] = cleaned_perfume_df['rating'] * cleaned_perfume_df.iloc[:, 7:]\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "cleaned_perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the string representations of dictionaries in 'main accords' into separate columns\n",
    "accords_df = cleaned_perfume_df['main accords'].apply(lambda x: pd.Series(eval(x)))\n",
    "\n",
    "# Create multiple entries for each perfume based on the number of scents it has\n",
    "perfume_df = cleaned_perfume_df.loc[cleaned_perfume_df.index.repeat(accords_df.shape[1])]\n",
    "\n",
    "# Reset index to align with the duplicated rows\n",
    "accords_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate accords_df with perfume_df\n",
    "cleaned_perfume_df = pd.concat([perfume_df, accords_df], axis=1)\n",
    "\n",
    "# Create a new column for scent strength\n",
    "cleaned_perfume_df['scent_strength'] = cleaned_perfume_df['rating'] * cleaned_perfume_df.iloc[:, 7:]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "cleaned_perfume_df.drop(['main accords', 'rating', 'number_votes'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values, if any\n",
    "cleaned_perfume_df.dropna(inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "cleaned_perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95c3afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import specific dependencies for this block\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Feature scaling (Min-Max scaling)\n",
    "scaler = MinMaxScaler()\n",
    "accords_columns = [col for col in cleaned_perfume_df.columns if col not in ['rating', 'number_votes']]\n",
    "accords_scaled = scaler.fit_transform(cleaned_perfume_df[accords_columns])\n",
    "cleaned_perfume_df[accords_columns] = accords_scaled\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#These are the features\n",
    "X = cleaned_perfume_df.drop(['rating', 'number_votes'], axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = cleaned_perfume_df['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "cleaned_perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `StandardScaler()` module from scikit-learn to normalize the data from the database\n",
    "\n",
    "# Review the scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the scaled data\n",
    "\n",
    "# Copy the names from the original data\n",
    "\n",
    "# Set the identifier column as index\n",
    "\n",
    "# Display sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed59e9",
   "metadata": {},
   "source": [
    "Find the best value for k using the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc045d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the number of k-values from 1 to 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ce5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the inertia values\n",
    "\n",
    "# Create a for loop to compute the inertia with each possible value of k\n",
    "# Inside the loop:\n",
    "# 1. Create a KMeans model using the loop counter for the n_clusters\n",
    "# 2. Fit the model to the data using `market_scaled`\n",
    "# 3. Append the model.inertia_ to the inertia list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the data to plot the Elbow curve\n",
    "\n",
    "# Create a DataFrame with the data to plot the Elbow curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a line chart with all the inertia values computed with \n",
    "# the different values of k to visually identify the optimal value for k using hvplot\n",
    "\n",
    "# Show the line chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba7940",
   "metadata": {},
   "source": [
    "The best value for k is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570397f9",
   "metadata": {},
   "source": [
    "Cluster scent notes with K-means using the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model using the best value for k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the K-Means model using the scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the clusters to group the notes using the scaled data\n",
    "\n",
    "# Print the resulting array of cluster values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to the DataFrame with the predicted clusters\n",
    "\n",
    "# Display sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot using hvPlot by setting \n",
    "# `x=\"price_change_percentage_24h\"` and `y=\"price_change_percentage_7d\"`. \n",
    "# Color the graph points with the labels found using K-Means and \n",
    "# add the note name in the `hover_cols` parameter to identify \n",
    "# the cryptocurrency represented by each data point.\n",
    "\n",
    "# Show scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3a7b3",
   "metadata": {},
   "source": [
    "Optimize Clusters with Principal Component Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a53704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA model instance and set `n_components=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14385b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the PCA model with `fit_transform` to reduce to \n",
    "# three principal components.\n",
    "\n",
    "# View the first five rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247220b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the explained variance to determine how much information \n",
    "# can be attributed to each principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the explained variance ratios\n",
    "\n",
    "# Calculate the total explained variance\n",
    "\n",
    "# Print the total explained variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68159f1b",
   "metadata": {},
   "source": [
    "What is the total explained variance of the # principal components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99571e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with the PCA data\n",
    "\n",
    "# Copy the note names from the original data\n",
    "\n",
    "# Set the name column as index\n",
    "\n",
    "# Display sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c0c64",
   "metadata": {},
   "source": [
    "Find the best value for k using the PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e88285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the number of k-values from 1 to 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c54c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the inertia values\n",
    "\n",
    "# Create a for loop to compute the inertia with each possible value of k\n",
    "# Inside the loop:\n",
    "# 1. Create a KMeans model using the loop counter for the n_clusters\n",
    "# 2. Fit the model to the data using `df_pca`\n",
    "# 3. Append the model.inertia_ to the inertia list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the data to plot the Elbow curve\n",
    "\n",
    "# Create a DataFrame with the data to plot the Elbow curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a line chart with all the inertia values computed with \n",
    "# the different values of k to visually identify the optimal value for k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c077b",
   "metadata": {},
   "source": [
    "The best value for k when using the PCA data is:\n",
    "\n",
    "Does the best k value change between the PCA Data and the Original Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a620ddb8",
   "metadata": {},
   "source": [
    "Cluster Notes with K-means using the PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1104db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model using the best value for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the K-Means model using the PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bae009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the clusters to group the notes using the PCA data\n",
    "\n",
    "# Print the resulting array of cluster values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ea315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame with the PCA data\n",
    "\n",
    "# Add a new column to the DataFrame with the predicted clusters\n",
    "\n",
    "# Display sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ea62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot using hvPlot by setting \n",
    "# `x=\"PC1\"` and `y=\"PC2\"`. \n",
    "# Color the graph points with the labels found using K-Means and \n",
    "# add the note name in the `hover_cols` parameter to identify \n",
    "# the note represented by each data point.\n",
    "\n",
    "# Show the scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbbbe2e",
   "metadata": {},
   "source": [
    "Visualize and Compare the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ce140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite plot to contrast the Elbow curves\n",
    "# Arrange plots side by side for comparison\n",
    "\n",
    "# Show the composite plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite plot to contrast the clusters\n",
    "# Arrange plots side by side for comparison\n",
    "\n",
    "# Show the scatter plot comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
